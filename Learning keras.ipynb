{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Começo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré processamento de áudio\n",
    "Links:\n",
    "https://towardsdatascience.com/urban-sound-classification-part-2-sample-rate-conversion-librosa-ba7bc88f209a\n",
    "https://librosa.github.io/blog/2019/07/17/resample-on-load/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coloque o path do data set de treino na variável train_audio_path\n",
    "train_audio_path = 'train/train/audio'\n",
    "\n",
    "#escolha os labels de acordo com o data set\n",
    "labels = [\"yes\", \"no\", \"up\", \"down\", \"left\", \"right\", \"on\", \"off\", \"stop\", \"go\"]\n",
    "\n",
    "all_wave = [] #lista com os áudios\n",
    "all_label = [] #lista com cada categoria de áudio (label)\n",
    "\n",
    "for label in labels:\n",
    "    waves = [f for f in os.listdir(train_audio_path + '/' + label) if f.endswith('.wav')] #pega todos os arquivos .wav\n",
    "    pbar = tqdm(waves)\n",
    "    print(label)\n",
    "    for wav in pbar:\n",
    "        #basicamente resampling os audios de 16000 para 8000 e excluindo os com menos de 1 segundo de duração\n",
    "        samples, sample_rate = librosa.load(train_audio_path + '/' + label + '/' + wav, sr = 16000)\n",
    "        samples = librosa.resample(samples, sample_rate, 8000)\n",
    "        if(len(samples) == 8000):\n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)\n",
    "\n",
    "#convertendo as categorias (labels) em inteiros codificados\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(all_label)\n",
    "classes = list(le.classes_)\n",
    "\n",
    "#problema de classificação multipla precisa converter os inteiros acima em \"one-hot vector\"\n",
    "y = np_utils.to_categorical(y, num_classes = len(labels))\n",
    "\n",
    "#mudando o array de 2D para 3D por causa do conv1d - precisa ser 3D\n",
    "all_wave = np.array(all_wave).reshape(-1, 8000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separando os sets\n",
    "Treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Usa o train_test_split do sklearn para separar os sets\n",
    "#tr = train (treino)\n",
    "#val = validation (validação)\n",
    "#o modelo de treinamento vai usar 80% dos dados enquanto o de validação os 20% restantes\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(np.array(all_wave), np.array(y), stratify = y, test_size = 0.2, random_state = 777, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arquitetura\n",
    "Para construir o modelo será usado o Conv1d. O Conv1d é uma rede neural convolucional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construindo o modelo\n",
    "Link sobre earlystopping e modelcheckpoint: http://keras.io/callbacks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (8000, 1))\n",
    "\n",
    "#primeiro Conv1d layer\n",
    "conv = Conv1D(8,13, padding='valid', activation='relu', strides=1)(inputs)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#segundo Conv1d layer\n",
    "conv = Conv1D(16, 11, padding = 'valid', activation = 'relu', strides = 1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#terceiro Conv1d layer\n",
    "conv = Conv1D(32, 9, padding = 'valid', activation = 'relu', strides = 1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#quarto Conv1d layer\n",
    "conv = Conv1D(64, 7, padding = 'valid', activation = 'relu', strides = 1)(conv)\n",
    "conv = MaxPooling1D(3)(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#flatten layer\n",
    "conv = Flatten()(conv)\n",
    "\n",
    "#dense layer 1\n",
    "conv = Dense(256, activation = 'relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "#dense layer 2\n",
    "conv = Dense(128, activation = 'relu')(conv)\n",
    "conv = Dropout(0.3)(conv)\n",
    "\n",
    "outputs = Dense(len(labels), activation = 'softmax')(conv)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "#Define a função de perda como \"categorical cross-entropy\" pois é um problema de multiclassificação\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer ='adam', metrics = ['accuracy'])\n",
    "\n",
    "#\"EarlyStopping\" e \"ModelCheckpoints\" são callbacks para parar o treino da rede neural no momento certo e salvar o melhor modelo em toda epoch\n",
    "es = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 10, min_delta = 0.0001)\n",
    "mc = ModelCheckpoint('best_model.hdf5', monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma epoch é quando todo o dataset passa pela rede neural (de trás pra frente e da frente pra trás).\n",
    "Batch é a divisão do dataset.\n",
    "Batch size é o total de exemplos dentro de uma batch.\n",
    "Link: https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizar o model.fit para treinar o modelo por um número fixado de epochs\n",
    "history = model.fit(x_tr, y_tr, epochs = 100, callbacks = [es, mc], batch_size = 32, validation_data = (x_val, y_val))\n",
    "model.save('best_model.hdf5') #salvando modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carregar o modelo\n",
    "model = load_model('best_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#função para predição\n",
    "def predict(audio):\n",
    "    prob = model.predict(audio.reshape(1,8000,1))\n",
    "    index = np.argmax(prob[0])\n",
    "    return classes[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testando o modelo\n",
    "import random\n",
    "index=random.randint(0,len(x_val)-1)\n",
    "samples=x_val[index].ravel()\n",
    "print(\"Audio:\",classes[np.argmax(y_val[index])])\n",
    "ipd.Audio(samples, rate=8000)\n",
    "print(\"Text:\",predict(samples))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
